{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gtambi143/Naive-Bayes/blob/master/Naive_Bayes.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bjzmJ3olDB9m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing the important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9zSHdrWPDGPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#laod iris dataset\n",
        "iris_data = datasets.load_iris()\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(iris_data.data, iris_data.target, test_size = 0.33, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l7fxQcEqeL52",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Scikit learn will help here to build a Naive Bayes model in Python. There are three types of Naive Bayes model under scikit learn library:\n",
        "\n",
        "**Gaussian**: It is used in classification and it assumes that features follow a normal distribution.\n",
        "\n",
        "**Multinomial**: It is used for discrete counts. For example, let’s say,  we have a text classification problem. Here we can consider bernoulli trials which is one step further and instead of “word occurring in the document”, we have “count how often word occurs in the document”, you can think of it as “number of times outcome number x_i is observed over the n trials”.\n",
        "\n",
        "**Bernoulli**: The binomial model is useful if your feature vectors are binary (i.e. zeros and ones). One application would be text classification with ‘bag of words’ model where the 1s & 0s are “word occurs in the document” and “word does not occur in the document” respectively."
      ]
    },
    {
      "metadata": {
        "id": "B7OdRyaLe16f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Gaussian Naive Bayes**"
      ]
    },
    {
      "metadata": {
        "id": "UI5EfJWodpuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f1f821e-e4f9-46fe-b575-1df8d56f74cb"
      },
      "cell_type": "code",
      "source": [
        "model_nb_gaussian = naive_bayes.GaussianNB()\n",
        "\n",
        "model_nb_gaussian.fit(train_x, train_y)\n",
        "\n",
        "model_nb_gaussian.score(train_x, train_y)\n",
        "\n",
        "predicted_test = model_nb_gaussian.predict(test_x)\n",
        "                        \n",
        "metrics.accuracy_score(predicted_test, test_y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "8uqP3OvLlD7y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Bernaulli Naive Bayes**"
      ]
    },
    {
      "metadata": {
        "id": "Pp892RJaDJnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "736c4fdd-8fae-4c09-e67c-3f24601ccbf7"
      },
      "cell_type": "code",
      "source": [
        "# We cannot apply bernaulli here because we have 3 classes. Bernaulli is used for binaru classification. \n",
        "# consider this code as a sample code\n",
        "# Although this function has a parameter to binarize the data. It will make the input data binary if not.\n",
        "\n",
        "model_nb_bernaulli = naive_bayes.BernoulliNB(alpha=1.0, binarize=1.0, fit_prior=True, class_prior=None)\n",
        "\n",
        "model_nb_bernaulli.fit(train_x, train_y)\n",
        "\n",
        "model_nb_bernaulli.score(train_x, train_y)\n",
        "\n",
        "predicted_test = model_nb_bernaulli.predict(test_x)\n",
        "\n",
        "metrics.accuracy_score(predicted_test, test_y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "SZcUeftGmdgL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Multinomial Naive Bayes**"
      ]
    },
    {
      "metadata": {
        "id": "y8NOmPVfmYny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61b1a26-d545-42b4-e35f-a5b0fb5cb474"
      },
      "cell_type": "code",
      "source": [
        "model_nb_multinomial = naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
        "\n",
        "model_nb_multinomial.fit(train_x, train_y)\n",
        "\n",
        "model_nb_multinomial.score(train_x, train_y)\n",
        "\n",
        "predicted_test = model_nb_multinomial.predict(test_x)\n",
        "\n",
        "metrics.accuracy_score(predicted_test, test_y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}